{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and formatiing of data complete...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# code to replicate the performance of the NIPS'16 MLHC workshop paper \"Cam CNNS predict anatomy?\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from collections import deque\n",
    "from collections import OrderedDict\n",
    "from collections import Iterable\n",
    "\n",
    "# os.environ[\"THEANO_FLAGS\"] = \"device=gpu0,floatX=float32\" \n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "\n",
    "os.environ[\n",
    "    \"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda0,floatX=float32,force_device=true,exception_verbosity=high,lib.cnmem=0.9 ,nvcc.flags=-D_FORCE_INLINES\"\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from IPython.core.debugger import Tracer\n",
    "# Tracer()()\n",
    "K.set_image_dim_ordering('th')\n",
    "# K.image_dim_ordering('channels_first')\n",
    "#from keras.datasets import cifar10\n",
    "#keras.callbacks.Callback()\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Convolution2D, MaxPooling2D \n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.models import load_model\n",
    "from keras.datasets import mnist\n",
    "from scipy import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "def get_categorical_accuracy_keras(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.argmax(y_true, axis=1), K.argmax(y_pred, axis=1)))\n",
    "\n",
    "def load_data():\n",
    "    data = np.load('/work/vsankar/Project-Luna/Train_nf_n_0_rotated_data.npz')\n",
    "    X_train = data['X_train']\n",
    "    Y_train = data['Y_train']\n",
    "    \n",
    "    data = np.load('/work/vsankar/Project-Luna/Test_nf_n_0_rotated_data.npz')\n",
    "    X_test = data['X_test']\n",
    "    Y_test = data['Y_test']    \n",
    "    \n",
    "    data = np.load('/work/vsankar/Project-Luna/Val_nf_n_0_rotated_data.npz')\n",
    "    X_val = data['X_val']\n",
    "    Y_val = data['Y_val']\n",
    "    \n",
    "    return X_train,Y_train,X_test,Y_test,X_val,Y_val\n",
    "\n",
    "def model_architecture(img_rows,img_cols,img_channels,nb_classes):\n",
    "    #function defining the architecture of defined CNN\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same',init='orthogonal',dim_ordering='th',bias = True, input_shape=(img_channels,img_rows, img_cols)))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.25))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.25))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same',init='orthogonal',  dim_ordering='th',bias = True))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n",
    "    model.add(Convolution2D(96, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.25))\n",
    "\n",
    "    model.add(Convolution2D(96, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.25))\n",
    "\n",
    "    model.add(Convolution2D(96, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.5))\n",
    "\n",
    "    model.add(Convolution2D(512, 1, 1, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "\n",
    "#     model.add(BN(axis=1, momentum=0.99, epsilon=0.001))\n",
    "    Dropout((0.5))\n",
    "\n",
    "    model.add(Convolution2D(2, 1, 1, activation='relu', border_mode='same',init='orthogonal', dim_ordering='th', bias = True))\n",
    "    model.add(GlobalAveragePooling2D(dim_ordering='default'))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def normalize_date(X_train,Y_train,X_test,Y_test,X_val, Y_val,nb_classes):\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "    print(X_val.shape[0], 'val samples')\n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_val = X_val.astype('float32')\n",
    "    \n",
    "    Y_train = Y_train.astype('float32')\n",
    "    Y_test = Y_test.astype('float32')\n",
    "    Y_val = Y_val.astype('float32')\n",
    "\n",
    "#     normalizing the data\n",
    "    X_train /= 4095.0   \n",
    "    X_test /= 4095.0\n",
    "    X_val /= 4095.0\n",
    "    \n",
    "    #std\n",
    "#     X_train = X_train/np.std(X_train) - np.mean(X_train)\n",
    "#     X_test = X_test/np.std(X_test) - np.mean(X_test)\n",
    "    \n",
    "#     Tracer()()\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "    Y_val = np_utils.to_categorical(Y_val, nb_classes)\n",
    "    \n",
    "    \n",
    "    return X_train,Y_train,X_test,Y_test,X_val,Y_val\n",
    "\n",
    "def run(batch_size,nb_classes,nb_epoch,data_augmentation,img_rows, img_cols,img_channels,model_name):\n",
    "\n",
    "    \n",
    "    \n",
    "    print('Loading and formatiing of data complete...')\n",
    "    \n",
    "    #load the model defined in model_architecture function\n",
    "    model = model_architecture(img_rows,img_cols,img_channels,nb_classes)\n",
    "\n",
    "#     training the model using SGD + momentum\n",
    "#     adm = Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#     model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer=adm,\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "  \n",
    "    modelPath = \"/work/vsankar/Project-Luna/Luna_weights/luna_weights_t_ae5_nt_b128_d25_BN1_d3_3_rotated_best_dev_new.hdf5\"\n",
    "#     Tracer()()\n",
    "    model.load_weights(modelPath)\n",
    "#     model = load_model(modelPath, custom_objects={'get_categorical_accuracy_keras': get_categorical_accuracy_keras})\n",
    "#     Tracer()()\n",
    "#     model.predict( X_test, batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "    return model\n",
    "\n",
    "        # serialize model to JSON\n",
    "        \n",
    "model_name = 'luna_weights_t_ae5_nt_b128_d25_BN1_d3_3_rotated'     \n",
    "batch_size = 50\n",
    "nb_classes = 2\n",
    "nb_epoch = 30\n",
    "data_augmentation = True\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 96,96\n",
    "# the imgCLEF images are grey\n",
    "img_channels = 1\n",
    "model = run(batch_size,nb_classes,nb_epoch,data_augmentation,img_rows,img_cols,img_channels,model_name)\n",
    "# model_architecture(img_rows,img_cols,img_channels,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test,y_test,X_train,y_train,x_val,y_val = load_data()\n",
    "# nb_classes=2\n",
    "# X_train,Y_train,X_test,Y_test,X_val,Y_val = normalize_date(X_test,y_test,X_train,y_train,x_val,y_val,nb_classes)\n",
    "# np.save('/work/vsankar/Project-Luna/Test_data.npy', X_test,Y_test)\n",
    "\n",
    "\n",
    "X_testing = np.random.random_sample((5,1,96,96))\n",
    "# Y_testing = Y_test[1,:]\n",
    "\n",
    "\n",
    "# y = model.predict( X_testing, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "CorrMM images and kernel must have the same stack size\n\nApply node that caused the error: CorrMM{half, (1, 1), (1, 1)}(convolution2d_input_2, Subtensor{::, ::, ::int64, ::int64}.0)\nToposort index: 29\nInputs types: [TensorType(float32, 4D), TensorType(float32, 4D)]\nInputs shapes: [(1, 1, 96, 96), (3, 3, 1, 32)]\nInputs strides: [(36864, 36864, 384, 4), (384, 128, -128, -4)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: [11, 11]\nOutputs clients: [[Elemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](TensorConstant{(1, 1, 1, 1) of 0.5}, CorrMM{half, (1, 1), (1, 1)}.0, InplaceDimShuffle{x,0,x,x}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-3-9e83bf0ec61a>\", line 77, in model_architecture\n    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same',init='orthogonal',dim_ordering='th',bias = True, input_shape=(img_channels,img_rows, img_cols)))\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/models.py\", line 299, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 401, in create_input_layer\n    self(x)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 475, in call\n    filter_shape=self.W_shape)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1520, in conv2d\n    filter_shape=filter_shape)\n\nDebugprint of the apply node: \nCorrMM{half, (1, 1), (1, 1)} [id A] <TensorType(float32, 4D)> ''   \n |convolution2d_input_2 [id B] <TensorType(float32, 4D)>\n |Subtensor{::, ::, ::int64, ::int64} [id C] <TensorType(float32, 4D)> ''   \n   |convolution2d_13_W [id D] <TensorType(float32, 4D)>\n   |Constant{-1} [id E] <int64>\n   |Constant{-1} [id E] <int64>\n\nStorage map footprint:\n - convolution2d_22_W, Shared Input, Shape: (3, 3, 96, 128), ElemSize: 4 Byte(s), TotalSize: 442368 Byte(s)\n - convolution2d_21_W, Shared Input, Shape: (3, 3, 96, 96), ElemSize: 4 Byte(s), TotalSize: 331776 Byte(s)\n - convolution2d_20_W, Shared Input, Shape: (3, 3, 96, 96), ElemSize: 4 Byte(s), TotalSize: 331776 Byte(s)\n - convolution2d_23_W, Shared Input, Shape: (1, 1, 128, 512), ElemSize: 4 Byte(s), TotalSize: 262144 Byte(s)\n - convolution2d_19_W, Shared Input, Shape: (3, 3, 64, 96), ElemSize: 4 Byte(s), TotalSize: 221184 Byte(s)\n - convolution2d_17_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - convolution2d_18_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - convolution2d_16_W, Shared Input, Shape: (3, 3, 32, 64), ElemSize: 4 Byte(s), TotalSize: 73728 Byte(s)\n - convolution2d_input_2, Input, Shape: (1, 1, 96, 96), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - convolution2d_14_W, Shared Input, Shape: (3, 3, 32, 32), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - convolution2d_15_W, Shared Input, Shape: (3, 3, 32, 32), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - convolution2d_24_W, Shared Input, Shape: (1, 1, 512, 2), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - convolution2d_23_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - Subtensor{::, ::, ::int64, ::int64}.0, Shape: (3, 3, 1, 32), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - convolution2d_13_W, Shared Input, Shape: (3, 3, 1, 32), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - convolution2d_22_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - convolution2d_20_b, Shared Input, Shape: (96,), ElemSize: 4 Byte(s), TotalSize: 384 Byte(s)\n - convolution2d_21_b, Shared Input, Shape: (96,), ElemSize: 4 Byte(s), TotalSize: 384 Byte(s)\n - convolution2d_19_b, Shared Input, Shape: (96,), ElemSize: 4 Byte(s), TotalSize: 384 Byte(s)\n - convolution2d_16_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_17_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_18_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_13_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - convolution2d_14_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - convolution2d_15_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - convolution2d_24_b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Constant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1) of 0.5}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1, 1) of 0.5}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n TotalSize: 2078696.0 Byte(s) 0.002 GB\n TotalSize inputs: 2078696.0 Byte(s) 0.002 GB\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-faf7c10b2890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1272\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: CorrMM images and kernel must have the same stack size\n\nApply node that caused the error: CorrMM{half, (1, 1), (1, 1)}(convolution2d_input_2, Subtensor{::, ::, ::int64, ::int64}.0)\nToposort index: 29\nInputs types: [TensorType(float32, 4D), TensorType(float32, 4D)]\nInputs shapes: [(1, 1, 96, 96), (3, 3, 1, 32)]\nInputs strides: [(36864, 36864, 384, 4), (384, 128, -128, -4)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: [11, 11]\nOutputs clients: [[Elemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](TensorConstant{(1, 1, 1, 1) of 0.5}, CorrMM{half, (1, 1), (1, 1)}.0, InplaceDimShuffle{x,0,x,x}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-3-9e83bf0ec61a>\", line 77, in model_architecture\n    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same',init='orthogonal',dim_ordering='th',bias = True, input_shape=(img_channels,img_rows, img_cols)))\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/models.py\", line 299, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 401, in create_input_layer\n    self(x)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 475, in call\n    filter_shape=self.W_shape)\n  File \"/home/vsankar/pyenvs/LungCancerDev/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1520, in conv2d\n    filter_shape=filter_shape)\n\nDebugprint of the apply node: \nCorrMM{half, (1, 1), (1, 1)} [id A] <TensorType(float32, 4D)> ''   \n |convolution2d_input_2 [id B] <TensorType(float32, 4D)>\n |Subtensor{::, ::, ::int64, ::int64} [id C] <TensorType(float32, 4D)> ''   \n   |convolution2d_13_W [id D] <TensorType(float32, 4D)>\n   |Constant{-1} [id E] <int64>\n   |Constant{-1} [id E] <int64>\n\nStorage map footprint:\n - convolution2d_22_W, Shared Input, Shape: (3, 3, 96, 128), ElemSize: 4 Byte(s), TotalSize: 442368 Byte(s)\n - convolution2d_21_W, Shared Input, Shape: (3, 3, 96, 96), ElemSize: 4 Byte(s), TotalSize: 331776 Byte(s)\n - convolution2d_20_W, Shared Input, Shape: (3, 3, 96, 96), ElemSize: 4 Byte(s), TotalSize: 331776 Byte(s)\n - convolution2d_23_W, Shared Input, Shape: (1, 1, 128, 512), ElemSize: 4 Byte(s), TotalSize: 262144 Byte(s)\n - convolution2d_19_W, Shared Input, Shape: (3, 3, 64, 96), ElemSize: 4 Byte(s), TotalSize: 221184 Byte(s)\n - convolution2d_17_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - convolution2d_18_W, Shared Input, Shape: (3, 3, 64, 64), ElemSize: 4 Byte(s), TotalSize: 147456 Byte(s)\n - convolution2d_16_W, Shared Input, Shape: (3, 3, 32, 64), ElemSize: 4 Byte(s), TotalSize: 73728 Byte(s)\n - convolution2d_input_2, Input, Shape: (1, 1, 96, 96), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - convolution2d_14_W, Shared Input, Shape: (3, 3, 32, 32), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - convolution2d_15_W, Shared Input, Shape: (3, 3, 32, 32), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)\n - convolution2d_24_W, Shared Input, Shape: (1, 1, 512, 2), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - convolution2d_23_b, Shared Input, Shape: (512,), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - Subtensor{::, ::, ::int64, ::int64}.0, Shape: (3, 3, 1, 32), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - convolution2d_13_W, Shared Input, Shape: (3, 3, 1, 32), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)\n - convolution2d_22_b, Shared Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)\n - convolution2d_20_b, Shared Input, Shape: (96,), ElemSize: 4 Byte(s), TotalSize: 384 Byte(s)\n - convolution2d_21_b, Shared Input, Shape: (96,), ElemSize: 4 Byte(s), TotalSize: 384 Byte(s)\n - convolution2d_19_b, Shared Input, Shape: (96,), ElemSize: 4 Byte(s), TotalSize: 384 Byte(s)\n - convolution2d_16_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_17_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_18_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - convolution2d_13_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - convolution2d_14_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - convolution2d_15_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - convolution2d_24_b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - Constant{3}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1) of 0.5}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1, 1) of 0.5}, Shape: (1, 1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n TotalSize: 2078696.0 Byte(s) 0.002 GB\n TotalSize inputs: 2078696.0 Byte(s) 0.002 GB\n\n"
     ]
    }
   ],
   "source": [
    "X_testing = np.random.random_sample((5,1,96,96))\n",
    "y = model.predict(X_testing, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[1:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as m\n",
    "from IPython.core.debugger import Tracer;\n",
    "Threshold = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "i=0\n",
    "sen_tpr=np.zeros(len(Threshold))\n",
    "spc_tnr=np.zeros(len(Threshold))\n",
    "acc=np.zeros(len(Threshold))\n",
    "tn=np.zeros(len(Threshold))\n",
    "fp=np.zeros(len(Threshold))\n",
    "fn=np.zeros(len(Threshold))\n",
    "tp= np.zeros(len(Threshold))\n",
    "for t in Threshold:\n",
    "#      Tracer()() \n",
    "    y_pred = y.copy()\n",
    "    y_true = Y_test\n",
    "    y_pred[y_pred>=t]=1\n",
    "#     Tracer()()\n",
    "    y_pred[y_pred<t] = 0\n",
    "    \n",
    "    cm = m.confusion_matrix(y_true[:,1], y_pred[:,1])\n",
    "#     Tracer()()\n",
    "    \n",
    "    tn[i], fp[i], fn[i], tp[i] = cm.ravel().astype('float32')\n",
    "    \n",
    "    \n",
    "    sen_tpr[i]=tp[i]/(tp[i]+fn[i])\n",
    "    spc_tnr[i] = tn[i]/(tn[i]+fp[i])\n",
    "    acc[i] = (tp[i] +tn[i])/(tn[i]+tp[i]+fp[i]+fn[i])\n",
    "#     from IPython.core.debugger import Tracer; Tracer()() \n",
    "    i=i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_tpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn,tp,fp,fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_tnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypint = np.packbits(y.astype('int'),axis=-1)\n",
    "ytrueint = np.packbits(Y_test.astype('int'),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.astype('float32'),Y_test.astype('float32')\n",
    "ypint,ytrueint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as m\n",
    "print( \"accuracy is = \" )\n",
    "print (m.accuracy_score(ypint, ytrueint))\n",
    "print( \"confusion matrix is \")\n",
    "print (m.confusion_matrix( ytrueint,ypint))\n",
    "print (\"roc is \")\n",
    "fpr, tpr, thresholds = m.roc_curve(ytrueint, ypint, pos_label=2)\n",
    "print(\"fpr = \")\n",
    "print(fpr),\n",
    "print(\" tpr = \" )\n",
    "print(tpr)\n",
    "print(\" thresholds = \")\n",
    "print(thresholds)\n",
    "roc_auc = m.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[1:200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/work/vsankar/Project-Luna/Test_data.npy', X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/work/vsankar/Project-Luna/Test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test,X_train,y_train = load_data()\n",
    "# X_train,Y_train,X_test,Y_test = normalize_date(X_train,y_train,X_test,y_test,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train>1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " np.count_nonzero(y_test) - 2510\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LungCancerDev",
   "language": "python",
   "name": "lungcancerdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
